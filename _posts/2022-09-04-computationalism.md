---
layout: page
title: We Aren't Just Computation (and We Don't Even Know What We Don't Know)
summary: If people are just computers, then why do we have morality?
author:  AaronHertzmann
image: /images/wica/bradford_viewers.jpg
og:image: /images/wica/bradford_viewers.jpg
---


# We Aren't Just Computers (and We Don't Even Know What We Don't Know)



By the late 19th Century, physicists had derived physical laws for mechanics, optics, sound, fluids, and electromagnetics that predicted experimental data so well that they thought they might soon be done. Albert Michaelson wrote that "it seems probable that most of the grand underlying principles have been firmly established ... the future truths of physical science are to be looked for in the sixth place of decimals." All that remained in physics was to dot a few i's, cross a few t's, and measure a few things more precisely. Other physicists weren't so sure, like Lord Kelvin who wrote about certain irreconciable problems in physics. 

In order to fill in some of these measurement gaps, [Michaelson and Morley conducted experiments](https://en.wikipedia.org/wiki/Michelson%E2%80%93Morley_experiment) to measure the speed of light, and their experiments ultimately led to relativity theory, which completely toppled our previous understanding of physics.  It was if, in trying to close the last few windows in a chilly house, physicists discovered that an entire side of the house was missing.

When I talk about how [computers can't be artists](https://cacm.acm.org/magazines/2020/5/244330-computers-do-not-make-art-people-do/fulltext), **people sometimes respond "But aren't we just computers?" 
I believe this statement, seductive to so many people, is misguided and misleading.**  We live in a time of stunning advances in machine learning, robotics, and neuroscience. But when people say that brains are just computers, to me they sound like Michaelson, underestimating just how little we know.


# We Don't Know What We Don't Know

What is consciousness? What is intelligence? What make you a person? 

We have no idea.

We have all sorts of [interesting theories](https://www.nature.com/articles/s41583-022-00587-4), and lots of active research, but we really do not know. These questions are complex and multifaceted: there are many kinds of intelligence. We don't even know what question we're asking... what exactly is a person anyways?

We have a long history of this kind of "[computationalism](https://twitter.com/chazfirestone/status/1565080804497035264)." The AI pioneers of the 1960s vigorously argued that intelligence could be modeled only with symbolic reasoning, and fought tooth-and-nail against the advocates of neural networks. They were sure that symbolic reasoning was all we needed. Now [Transformers are all you need](https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html).

What is the difference? We're obviously not computers on a purely physical level: we operate with spiking neurons and chemical signalling, and possibly other unknown mechanisms. Quantum mechanics might play an important role. But [maybe these low-level processes could all be simulated in a sufficiently-powerful binary computer](https://www.nytimes.com/2015/06/28/opinion/sunday/face-it-your-brain-is-a-computer.html); we don't know.



**False equivalences**

We are _like_ computers in many ways. This analogy provides an immensely-useful way to understand people and understand our brains. Computational thinking has lead to many breakthroughs in neuroscience and cognitive science;
I've used some of these ideas in my research, such as the way [artificial neural networks model early vision](https://www.nature.com/articles/nn.4244) and [Bayesian models of cognition](https://en.wikipedia.org/wiki/Bayesian_cognitive_science). But it is just an analogy for the brain, not equivalence. One can make many similar analogies with varying degrees of usefulness and absurdity.

In the 19th century, with the development of thermodynamics, we began to understand that people are like steam engines: you need to feed in fuel that can be burned; the potency of fuel is measured in units of heat, like calories. Now we are careful with how many calories that we eat. It's a useful analogy, but it doesn't mean that we're just steam engines.

Modern computers are made with silicon (sand). Rocks are basically sand. But [rocks are not computers](https://twitter.com/Grady_Booch/status/1564795248764588034).


**Emergence** 

The [_emergence_](https://en.wikipedia.org/wiki/Emergence) concept expresses the way a complex system can exhibit behaviors that you can't understand just by looking at the parts.  Aggreggate systems exhibit hard-to-predict behaviors. When Michaelson said physics was almost done, in fact even classical mechanics had a long way to go: even when you know the basic rules of a system, like Newton's Laws, understanding the aggregate behavior remains hard. You can't just directly predict how a fluid will flow from fundamental laws. An entire field, [chaos theory](https://en.wikipedia.org/wiki/Chaos_theory), studies this difficulty. Even seemingly-simple things like [why bicycles work](http://ruina.tam.cornell.edu/research/topics/bicycle_mechanics/overview.html) were hard to figure out, and there are many physical systems that we still struggle to truly understand.

Perhaps our humanity emerges from the complexity of neural systems embodied in the physical world: a neuron is not a person, and a group of neurons is not a person, but enough of them together create behaviors that they could not on their own. But, even as a theory of consciouness, emergence [is so vague as to be uninformative](https://www.nature.com/articles/s41583-022-00587-4), it's a ["then a miracle occurs"](https://www.researchgate.net/profile/Michael-Wade-5/publication/302632920/figure/fig2/AS:751645805789184@1556217733527/Then-a-Miracle-Occurs-Copyrighted-artwork-by-Sydney-Harris-Inc-All-materials-used-with.png) leap from low-level circuity to creativity, intelligence, and culture.

Modern neural networks are just matrix multiplication with thresholding.  They do exhibit interpretable behavior in cases; the work of [Zeiler and Fergus](https://link.springer.com/chapter/10.1007/978-3-319-10590-1_53) and [David Bau](https://baulab.info/) provides useful analyses of what kinds of functions they're learning. But they're learning things like image feature detectors, not how to be people.

Perhaps human-like behaviors will emerge from neural networks. I really don't think so. But this won't come from the kinds of training that is used to train current neural networks. People even credit systems like DALL-E with this kind of emergent behavior, when they are just _supervised learning_ (weakly). They're data-fitting, just like one might have learned in a 1950's statistics class (but far more powerful). But this is a remote possibility, which so many people seem to be treating accepted as fact.

These things are just code, they follow instructions, and they are not set up to do anything but optimize a loss function like ["fit this caption data"](https://twitter.com/model_mechanic/status/1519621946232610817?lang=en) or "walk without falling in simulation." We have no idea how to train an algorithm to be a person. We have no idea what that even would mean.



# What does it mean to be a person?

Some of the people saying "computers can be artists because we're computers" seem to be techies who think that art is just a matter of making novel pictures that people like. But we [already have algorithms that can do this](/2021/04/19/questons-for-computational-creativity.html).  If you just look at outputs, you could say DALL-E can produce good output in a broader range of styles faster than any living artist. But no one takes it seriously as an independent artist in its own right. (This is not to say that it could replace human artists, [using DALL-E is itself a creative, artistic activity](/2022/05/25/dall-e.html)).

I believe [we care about art because we care about our human relationships](/2021/03/22/art-is-social.html).  

Why do you care about other people? Why do people have lifelong friends and get married? Why do you give gifts and spend time with people?

We care about relationships because we are social beings, as a product of our evolution. And we care about other people because they're people.

What makes someone a person and not just a machine? No one knows. Social systems and behavior arose from evolution, but that's not enough of an answer.   The answer surely involves evolution, biology, psychology, evolution, and not just computing.


**Morality**

**The clearest demonstration of the gap is that we have morality about other people, and not computers. Why?**  If people are just computers, then why isn't it ok to kill people, but it is okay to turn off computers, to start programs and stop them, to spawn processes and then "kill" them?

Someone who thinks that other people are just bags of meat carrying computers in their skulls, with no more moral status than a laptop, is a sociopath.  Someone who thinks that a computer has the same rights and moral status as a person, and that turning off a computer is murder, is a nutjob.  If we are just computers, and nothing more, then these are the moral consequences.

Historically, we have granted moral status across ever-larger circles: to our own tribe in prehistory, to our own political units in ancient history, to all humans in modern history, and, to some extent, animals. We have not granted  moral status to any inanimate objects (although some environmentalism describes itself this way). We don't  give just anything rights, and we're not giving computers rights.


**These are ancient questions**

These ideas are new versions of an old questions: the question of free will and determinism. If you believe in [materialism](https://en.wikipedia.org/wiki/Materialism), the notion that we live in a world governed by physical laws without divine guidance, then, at some level, we are all just bags of atoms bouncing around and obeying physics. How can we have [free will](https://en.wikipedia.org/wiki/Free_will)?  In other words, aren't we just physical systems obeying physical laws, like computers or steam engines or waterfalls? Philosophers have asked this question for centuries. Theologians have long debated versions of this question, such as: [if God created us, then isn't he responsible for everything we do?](https://en.wikipedia.org/wiki/Free_will_in_theology)

The question is old, and possibly unsolvable. The last ten years of progress in deep learning hasn't really changed this difficult old problem. Yet, even though we can't answer the free will question, we still go about our lives believing in our own ability and others' to make decisions, and the importance of our social and moral relationships.


# It's science fiction

The idea that we will have sentient, intelligent, and conscious machines fascinates us, after decades of science fiction stories depicting it. But we are nowhere near creating such systems; it remains science fiction.

We don't know enough to think throgh the implications of art-making computers, because we don't know enough of what that world will look like. Imagine if Jules Verne tried to think about a world with computers. He might imagine Difference Engines that fit in the palms of our hands, carried about by Victorian dandies on their horse-drawn carriages. It's so hard to imagine how one technology can radically transform our world so as to be unrecognizable, and even harder to anticipate all the technological and societal changes that happen together.

Working out the nuances of art-making computers is like trying to work out the political system for our future space colonies. Maybe it's a fun science fiction exercise, but we know so little about what a space colony might be like and what our technology and society will be like then—or even if it's possible at all—that it's an exercise unconnected to the reality of whatever that distant hypothetical situation might be.

And all this talk of conscious, artistic machines distracts from the urgant societal and ethical questions around the use of these software algorithms misleadingly called "artificial intelligence" in our real world.







