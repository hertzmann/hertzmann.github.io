---
layout: page
title: Creative Explorations with DALL-E 2
summary: What does this new demo mean for AI-generated art and creativity?
author:  AaronHertzmann
image: "/images/dall-e/DALL·E 2022-05-12 22.27.21.jpg"
og:image: "/images/dall-e/DALL·E 2022-05-12 22.27.21.jpg"
---

# Creative Explorations with DALL-E 2

I've been playing with [DALL-E 2, a new text-to-image demo from OpenAI](https://openai.com/dall-e-2/).  DALL-E 2 is _so much fun_. It's a rabbit-hole of creative play and a glimpse into future power tools for imaging.  With it came all the usual bad takes of, on one hand, AI making artists obsolete, and, on the other, AI art not being art at all. Nonetheless, DALL-E challenged my understanding of where we are with computer-generated imagery and computational creativity.  
 
Here are some of the image series that I've created with DALL-E:

* **Images in the styles of contemporary and modern artists:** [Facebook](https://www.facebook.com/aaron.hertzmann/posts/pfbid0ywgbrfeaAr3R7YijT6wwabTZdVwWe1w46A92VapEmQTDLbipg8nMxFxY2bZUwrxAl), [Twitter](https://twitter.com/AaronHertzmann/status/1524600741578506240).
* Three architectural series, made with [Manuel Ladron de Guevara](https://manuelladron.com/): 
	- **New buildings in the styles of famous architects:** [Facebook](https://www.facebook.com/aaron.hertzmann/posts/pfbid0Emc3XhL9ao7xZXB2skamZd3LUx7UKdAA4F5HioacYAHAMsad7ioS6Y7Z36DiPy5fl), [Twitter](https://twitter.com/AaronHertzmann/status/1526205494624284672).
	- **Fanciful homes, near or under water:** [Facebook](https://www.facebook.com/aaron.hertzmann/posts/pfbid0hztiGUZ2jgoDpMiVsTEftCeBBWbbbJECqEJMW3YqVuwnoTUG9XvgEFZi8ubgifRKl), [Twitter](https://twitter.com/AaronHertzmann/status/1526710430751522817?s=20&t=q9WSyjMbYXdViQxnEyLc6w).
	- **Public art in Lands End, SF:** [Facebook](https://www.facebook.com/aaron.hertzmann/posts/pfbid02VsMrCuHpb4XeeRgQKPmtPon6TrMcaVBXYVvS1bYPnJLeyWmsfzVN57rK27hrC2vrl), [Twitter](https://twitter.com/AaronHertzmann/status/1527069568174157825?s=20&t=q9WSyjMbYXdViQxnEyLc6w).
* **Reimagining classic computer graphics imagery:**
[Facebook](https://www.facebook.com/aaron.hertzmann/posts/pfbid0rhSepoRooUrHTbUnxnojDnEcdFCWHBqmq1prUirChHovdoRGEKFqAXgbJ54KArfwl), 
[Twitter](https://twitter.com/AaronHertzmann/status/1527743411351982081?s=20&t=q9WSyjMbYXdViQxnEyLc6w)
* **Making portrait images for people:** [Facebook](https://www.facebook.com/aaron.hertzmann/posts/pfbid02cmBHDdjdWWLJVfJ36kZhecRyW9FKwp1Fcu96ta42ngntRiLTTz3ChjkpQ3rXeZNal), [Twitter](https://twitter.com/AaronHertzmann/status/1529100591464521728)

Check them out!


This post shares some of my observations, and what DALL-E tells us about creativity and the future of image manipulation. Many people get the impression from these results that DALL-E can do anything and that it makes artists obsolete. I don't think either of these things are true, but it is nonetheless groundbreaking, a vivid indication of transformational technologies to come.

**My experimentation has been a form of _creative exploration_.** We often have the illusion that, when making art, an artist begins with a concrete goal and then executes on it. But, in many creative practices, one doesn't plan for a specific, concrete goal. Instead, one idea leads to another which leads to another, which leads one into new ideas completely unexpected from the starting point. DALL-E speeds up this acceleration, so you can iterate on some kinds of  visual ideas in minutes instead of hours, days, or weeks.
While DALL-E 2 isn't currently a good tool for achieving very focused or concrete tasks, it is an extraordinary power tool for creativity.



# What it does

DALL-E 2, like the previous text-to-image systems, generates an image from a piece of text. For example, when some friends and I gave it the text prompt _"cats in devo hats"_, it produced these 10 images:

![10 DALL-E results for "cats in devo hats"](../../../images/dall-e/cats-in-hats-10.jpg)
These images come in different styles, and nearly all of them look plausibly like real professional photographs or drawings; the algorithm does not know quite what a ["Devo hat"](https://en.wikipedia.org/wiki/Energy_dome) look like, but it's close.

I shared this one on social media:
<center>
	<a href="https://t.co/FJc9nLgjzT"><img src="../../../images/dall-e/DALL·E 2022-04-28 20.10.18.jpg" alt="Cats in Devo hats"></a>
</center>

Art hasn't felt this easy since the invention of the digital camera.


# What it can and can't do

[Even among the fast recent progress](/2021/03/11/lifecycle.html), DALL-E 2 seems like a significant advance. It isn't just making [indeterminate artistic imagery](https://direct.mit.edu/leon/article-abstract/53/4/424/96926/Visual-Indeterminacy-in-GAN-Art) or [realistic images in a few classes](https://github.com/NVlabs/stylegan), or other [artistic kinds of images](https://twitter.com/search?q=%23midjourney&src=typed_query&f=top); it produces many kinds of high-quality realistic or artistic images.

The initial images shared by OpenAI—by the influencers they first gave access to—gave the impression that OpenAI could do _anything_, because it could do so many things, because it could make things like this [_“Underwater shot of a baby goat's head eating a carrot, water bubbles, particulate, extremely detailed, studio lighting"_](https://labs.openai.com/s/wADzLCPvqNWQB10EqkP0C6Te)

![underwater goat image](../../../images/dall-e/underwater-goat.jpg)

Often, the best prompts used to generate the images themselves demonstrated tremendous creativity on the part of whomever used them, like  [_"An IT-guy trying to fix hardware of a PC tower is being tangled by the PC cables like Laokoon. Marble, copy after Hellenistic original from ca. 200 BC. Found in the Baths of Trajan, 1506":_](https://twitter.com/Merzmensch/status/1519294244279701505)

![IT guy sculpture](../../../images/dall-e/it-guy.jpg)


But there is some real [selection bias](https://en.wikipedia.org/wiki/Selection_bias) going on here. Hundreds of people are typing all sorts of zany and creative prompts into DALL-E. Only a fraction of those prompts produce awesome results, and the awesome images are the ones getting shared and going viral.  

As with any good artist, we're seeing just the very best results publicly, not all of them.  Even if every image that Claude Monet shares looks good, this does not mean he can make a good image of any style or subject.


[This blog post](https://www.lesswrong.com/posts/uKp6tBFStnsvrot5t/what-dall-e-2-can-and-cannot-do) gives a balanced analysis of what DALL-E does and doesn't do well, and [this report](https://arxiv.org/abs/2204.13807) discusses some specific tests of compositionality that DALL-E mostly fails at.

How well could you use DALL-E for image editing? Based on [the fiddly behavior of inpainting](https://www.youtube.com/watch?v=TFJLcy-pfTM), which sometimes works great, and but often [fails entirely](https://twitter.com/AaronHertzmann/status/1526581751979487232), I would guess it's not very reliable.  Which I suggests that it's not going to be reliable for many image manipulation tasks if it can't represent arbitrary images well in the model. 

Of course the technology is going to keep improving; this week, [Google announced Imagen](https://imagen.research.google/), a parallel effort using similar technology that claims even better results for photorealistic images.  


<center>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Our children will grow up taking for granted that computers can “simply” produce realistic images, entire stories, or chat with them naturally, while we think that it is magic.<br><br>Just like how our previous generations thought the radio, telephone, TV, video calls seem like magic. <a href="https://t.co/5tazufFWsC">pic.twitter.com/5tazufFWsC</a></p>&mdash; hardmaru (@hardmaru) <a href="https://twitter.com/hardmaru/status/1528317965002625027?ref_src=twsrc%5Etfw">May 22, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</center>

Is it possible that, some day, these algorithms will really be able to capture all the visual concepts we care about? To paraphase [Douglas Adams](https://youtu.be/Hv1spjsvu-A?t=7), the space of visual concepts is _big_. I mean, _really big_.

# How does it work?

There's a lot of mystique around AI software. But, as the first author of DALL-E says, [the method is quite conceptually simple](https://twitter.com/model_mechanic/status/1519621946232610817); it's [basically a statistical sampling algorithm](http://adityaramesh.com/posts/dalle2/dalle2.html). Philosophically, it's the kind of curve-fitting and model sampling that one might learn in a Statistics 101 class. However, it's curve fitting in high-dimensional spaces that's turbocharged with tasteful choices of modern algorithms, tons of model parameters, an unfathomably-large dataset, careful engineering, and collossal computation times. 

Personally, I think [we would be better off if we could avoid using the misleading term "Artificial Intelligence"](https://medium.com/center-on-privacy-technology/artifice-and-intelligence%C2%B9-f00da128d3cd) to describe these systems at all. It's all just software.

# Is it creative?

The DALL-E announcement vexed me a bit because I was just putting the finishing touches on [a paper on computational creativity](https://arxiv.org/abs/2205.01605). DALL-E appeared to make some points in my paper obsolete before it was even published.  In the paper, I point out that existing stroke-based painting algorithms have fixed painting styles, which is still _technically_ true but now irrelevant.

I had a moment early on while using DALL-E to generate different kinds of paintings, like "odilon redon painting of seattle": 
![10 DALL-E pictures of "odilon redon painting of seattle"](../../../images/dall-e/odilon-redon.jpg)
I thought, considering all the different painting styles I'd generated, (a) this is better than any painting algorithm I've ever developed, and (b) it's a better painter than I am.

In fact, no human can do what DALL-E does: create such a high-quality, varied range of images in mere seconds.  If someone told that you a person made those images from that prompt, of course you'd say they were creative.

But [I still maintain that this does not make DALL-E an artist](https://cacm.acm.org/magazines/2020/5/244330-computers-do-not-make-art-people-do/fulltext).  In the computational creativity community, some people have argued that computers could be considered creative, and that we can judge their creativity according to the novelty and quality of their outputs. By those measures, DALL-E has already surpassed humans. But, [as I've argued before, we've already got algorithms that produce high-quality, novel outputs](/2021/04/19/questons-for-computational-creativity.html); we can't judge creativity just by the outputs, though surely there are elements of human creativity here. The difference is that DALL-E can produce much more variety and sustain interest for much longer than previous methods.




# Creative processes as exploration

[In the new paper I mentioned](https://arxiv.org/abs/2205.01605), I point out a missing element in a lot of popular and academic conceptions of creativity: the role of open-ended exploration together with high-level goals. 

We often discuss artworks and inventions as though they result from the artist or inventor's goal. The artist intended to show a thing, or express an emotion, and so they made this image. But, when I began painting again a few years ago, [I found that my paintings came from the process, not from my goals](/2020/10/05/art-is-a-process.html). And, when I started to look around, I found numerous examples of artists and researchers describing their own processes in the same terms. [The paper](https://arxiv.org/abs/2205.01605) provides many examples and quotes from artists about how art and creativity isn't necessarily about intent.

One example is [this clip of Paul McCartney coming up with "Get Back"](https://www.youtube.com/watch?v=rUvZA5AYhB4&t=35s) in a jam session.  He didn't start with an idea of what the song was about, or what its intent is; he just started jamming and [went from there, including some abandoned variants along the way](https://en.wikipedia.org/wiki/Get_Back#Early_protest_lyrics).


# Finding my "style"

In my own explorations with DALL-E, one idea would lead to another which led to another, and eventually I'd find myself in a completely unexpected, magical new terrain, very far from where I'd started. [Stanley and Lehman](https://link.springer.com/book/10.1007/978-3-319-15524-1) describe discovery and creativity as a sequence of stepping stones, an apt analogy for this process. 

As one does with a new tool, I started playing around by generating zany prompts, probing and testing the system, and spending hours with friends coming up with new prompts and riffing off each others' ideas, like this _"Norman Rockwell portrait of a family of business cows":_

<a href="https://twitter.com/AaronHertzmann/status/1524436507980754944"><img src="../../../images/dall-e/business-cows.jpg" alt="Business cows"></a>

And, _"The Vitruvian Manatee by Leonardo da Vinci":_

<a href="https://twitter.com/AaronHertzmann/status/1524538184847085568"><img src="../../../images/dall-e/vitrivian-manatee.jpg" alt="vitruvian manatee"></a>

Something that week had made me think of the [contemporary painter Sarah Morris](https://en.wikipedia.org/wiki/Sarah_Morris). I figured we could try some more artists besides [the usual suspects](https://twitter.com/haltingproblem/status/1346846264940490754); I wondered if DALL-E knew her style, and [it did](https://twitter.com/AaronHertzmann/status/1524602412228513796?s=20&t=q9WSyjMbYXdViQxnEyLc6w). Then I started trying other contemporary painters. After running enough of these experiments, I put [these images into a single thread on social media](https://twitter.com/AaronHertzmann/status/1525155884053442560), while wondering how pleased and horrified these artists would be if they ever saw this.

Here's a "Sol LeWitt painting of an oscilloscope", since [Sol LeWitt](https://en.wikipedia.org/wiki/Sol_LeWitt) is an important precursor when talking about the history of generative art:

<a href="https://twitter.com/AaronHertzmann/status/1525155884053442560"><img src="../../../images/dall-e/DALL·E 2022-05-11 16.43.04.jpg" alt="Sol LeWitt DALL-E image"></a>

I began to see my experiments as "series," like artists' series: a consistent dive into a single theme, rather than a set of wacky random images. Other people can make better, more-viral images.  I think I have a bit of a subtler artistic style with these images; some of the image are like the things I like to paint, and maybe the style is close to my taste in art, since so much of making art with DALL-E is curating results.  And, comments, ideas, and collaboration from other people provided the best fuel for the fire. 

Ideas for these images and series came from all around, often linked in a series of stepping stones.  One of the final ideas in that first series was [a Yayoi Kusama installation](https://twitter.com/AaronHertzmann/status/1524600741578506240), and, after trying a few unsatisfactory locations for it, I hit on the idea of placing it in [La Mezquita](https://en.wikipedia.org/wiki/Mosque%E2%80%93Cathedral_of_C%C3%B3rdoba), in Córdoba, Spain. I sent the picture to an architect colleague, [Manuel Ladron de Guevara](https://manuelladron.com/), who is from Córdoba, and we began riffing on other architectural ideas together.  This became a series [on  buildings in different architects' styles](https://twitter.com/AaronHertzmann/status/1526205494624284672). 

<center>
<figure>
   <p float="left">
   <img src="../../../images/dall-e/DALL·E 2022-05-12 22.27.21.jpg" alt="selgascano pavilion in lands end, san francisco, made by dall-e"/>
</p>
  <figcaption align="center"><i><a href="https://twitter.com/AaronHertzmann/status/1527069568174157825">"selgascano pavilion in lands end, san francisco"</a></i></figcaption>
</figure>
</center>


The idea for my next series, based on [classic computer graphics images](https://twitter.com/AaronHertzmann/status/1527743411351982081?s=20&t=q9WSyjMbYXdViQxnEyLc6w), came from taking pictures on a drive up the California coast; a series of comments on [its Facebook post](https://www.facebook.com/aaron.hertzmann/posts/pfbid0rhSepoRooUrHTbUnxnojDnEcdFCWHBqmq1prUirChHovdoRGEKFqAXgbJ54KArfwl) led to the next series, [portraits of friends and colleagues](https://twitter.com/AaronHertzmann/status/1529100591464521728).
Here are two portraits. These came directly from the prompt the person provided, without iteration:

<center>
<figure>
   <p float="left">
   <img src="../../../images/dall-e/DALL·E 2022-05-19 17.57.02.jpg" alt="Portrait of Maxim Raginsky"/>
</p>
  <figcaption align="center"><i>Maxim Raginsky: <a href="https://twitter.com/mraginsky/status/1527672944712884225">"father, academic, raconteur, aging wannabe hipster in the style of Otto Dix”</a></i></figcaption>
</figure>
</center>

<center>
<figure>
   <p float="left">
   <img src="../../../images/dall-e/DALL·E 2022-05-20 14.11.11.jpg" alt="Portrait of Lyndie Chiou"/>
</p>
  <figcaption align="center"><i>Lyndie Chiou: <a href="https://twitter.com/AaronHertzmann/status/1529106447862145025">"Light skinned Black woman in a bookstore, writing on paper, with a crow nearby, the window shows it is dark outside but you can see the moon, in a gouache paint style"</a></i></figcaption>
</figure>
</center>

# Prompting as art

I've started to consider what I do with DALL-E to be both an exploration, and a form of art. In this, I am influenced by artists like [Ryan Murdoch](https://twitter.com/advadnoun) who have vigorously advocated for this kind of prompt-based image-making to be recognized as art. That doesn't mean that I'm making good art; it's amateur in the same sense that [the drawings I make on my iPad](https://www.instagram.com/aaronhertzmann/) are unpaid amateur art.

Working with DALL-E, or any of the text-to-image systems, means learning its quirks, developing strategies for avoiding common pitfalls, knowing about its biases ([some of which are harmful](https://github.com/openai/dalle-2-preview/blob/main/system-card.md#bias-and-representation), and some are quite hidden) and [built-in correlations](https://twitter.com/AaronHertzmann/status/1529220842441175042), like the way everything becomes old-timey when you select an old painter of photographer's style. 



You can look at the comment threads on [this Facebook post](https://www.facebook.com/aaron.hertzmann/posts/pfbid02cmBHDdjdWWLJVfJ36kZhecRyW9FKwp1Fcu96ta42ngntRiLTTz3ChjkpQ3rXeZNal)—and read the prompts in the screenshots—to see some examples of this process is action.


Meeting very specific, concrete goals is often frustrating (make a portrait look just like a specific person, or arrange these five items in a specific way).
Sometimes I can find a good image, especially if my goals are vague, but always the process will be delightful, and offer up surprises that lead to new ideas that themselves lead to more ideas and more and more.

It's too early to judge the significance of this art form. A phrase from the excellent book [_Art in the After-Culture_](https://www.haymarketbooks.org/books/1662-art-in-the-after-culture) keeps sticking in my head: "The dominant AI aesthetic is novelty."   Surely this would be true, to some extent, for any new technology used for art.  The [first films by the Lumière brothers](https://www.youtube.com/watch?v=4nj0vEO4Q6s) weren't cinematic novelties; it was amazing to see the images moving at all. (That quote comes from a chapter critiquing the way AI art benefits big technology companies.) Given[how fast AI art develops](https://aaronhertzmann.com/2021/03/11/lifecycle.html), it seems each year we're exploring an exciting new AI art technology, more impressive than the last.
